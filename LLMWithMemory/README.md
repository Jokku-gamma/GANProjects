📝 LLM having Memory with Llama 2 and Streamlit
This is a simple Streamlit LLM app having memory using the Llama 2 language model.

🚀 Quick Start
Download the Llama 2 Model:
Get llama-2-7b-chat.ggmlv3.q2_K.bin from Hugging Face and put it in your project folder.

Install requirements:
Make sure you have a requirements.txt file with:

streamlit
langchain
ctransformers
Then run:

Bash

pip install -r requirements.txt
Run the app:

Bash

streamlit run main.py
